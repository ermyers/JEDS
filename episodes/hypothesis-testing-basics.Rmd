---
title: "Hypothesis testing basics"
author: "Greg Maurer, Darren James"
date: '2022-06-19'
output:
    html_document:
      toc: true
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction

(@Greg @Darren - this is the old outline for the workshop, we can update this
or have this on the [workshop page](../workshops/20220628-ecology-short-course.Rmd)

Hypothesis testing is...

We will cover:

* P values
* Common pitfalls
* Making inferences
* Understanding approximations underlying the analysis approach
* Rencher & Schaalje P-value interpretations
* Information-theoretic approaches

### Our data and R packages

You will need to have the `car` package installed, which adds additional options
and specifications to fitted regression models, such as type-II and -III ANOVA 
output tables. You will also need `emmeans` to do post-hoc comparisons of groups
in fitted linear models, and `lme4` to fit some mixed models.

Data for the exercises here come from the Jornada annual NPP data package on
EDI. You can learn more about this dataset on the [teaching datasets]('./teaching_datasets.Rmd#Teaching-dataset-1') page. To load the data we will first load the `tidyverse`, then use `read_csv()`
function to read in the data from EDI:

```{r load_data, message=FALSE}
library(tidyverse)

anpp.annual <- read_csv('https://pasta.lternet.edu/package/data/eml/knb-lter-jrn/210011003/105/127124b0f04a1c71f34148e3d40a5c72')
```

## Comparing two samples

```{r, include=FALSE}
##
## Comparing two samples
##
```

We commonly need to compare two samples from a set of observations. Today we are
examining net primary production data (NPP) at the Jornada, so lets compare 
observations made in 2019 and 2020 and see if they are different using a
t-test.

First lets create a dataframe that is subset of the data from our larger
dataset.

```{r}
# Create a 2-year data subset
anpp.2019.2020 <- anpp.annual %>%
  dplyr::filter(year %in% 2019:2020)
```

In t-tests we are usually testing whether the mean of the two groups is
different. Lets look at some summary statistics first.

```{r}
# Summary statistics
anpp.2019.2020.stats <- anpp.2019.2020 %>%
  group_by(year) %>%
  summarise(n = n(),
            mean = mean(npp_g_m2),
            std.dev = sd(npp_g_m2)) %>%
  mutate(std.err = std.dev/sqrt(n))

anpp.2019.2020.stats
```
From this we see that the means for each year are offset, increasing by about 
16-19$g\cdot m^{-2}$ from 2018 to 2020. There are also differences in the
variance around the means, shown in different standard deviation and error
statistics.

For the t-test we will first need to put data into "wide" form, with
observations for each year in separate columns. Lets also calculate the
difference between years.

```{r}
# Spread to wide form
anpp.2019.2020.wide <- anpp.2019.2020 %>%
  spread(year, npp_g_m2)

head(anpp.2019.2020.wide)
```

Now do a t-test of differences in mean NPP in 2019 and 2020

```{r}
# A default 2-sample t-test in R
t.test(x = anpp.2019.2020.wide$`2019`, 
       y = anpp.2019.2020.wide$`2020`)
```
We see that the default here is a "Welch Two Sample t-test", which is
an unequal variance test. That means that the test is designed to account for 
differences in variance between the 2019 and 2020 sample. We'll se later that
this testing samples with different variances is something a mixed model would
alsodo. This test is telling us that there isn't a "significant" difference in
the means since the p-value is greater than 0.05. 

Lets look at some other t-tests. First, a standard Student's t-test with equal,
or pooled, variance.

```{r}
# t-test with equal variance
t.test(x = anpp.2019.2020.wide$`2019`, 
       y = anpp.2019.2020.wide$`2020`, 
       var.equal = TRUE)
```
This lowers the p-value a tad, but is that a good thing? We've pooled the
variance for 2019 and 2020, even though we saw from our summary statistics that
the variances might be unequal, i.e., the std. deviation of the 2020
observations are higher.

Next lets try a paired t-test, which assumes that the observations in each
sample are not independent. We know this is the case since we're measuring the 
same sites each year, and therefore comparing two samples of the same 
experimental or statistical units. In a paired test, we are testing whether the
difference between the 2019 and 2020 samples is different than zero. If we know
that we have unequal variances between samples, taking the difference is a
quick way to get around the issue.

```{r}
# Paired t-test
t.test(x = anpp.2019.2020.wide$`2019`, 
       y = anpp.2019.2020.wide$`2020`, 
       paired = TRUE)
```
We have a significant result here (p-value < 0.05) which tells us that we can
reject the null hypothesis that the difference between these two years of data
is equal to zero. So, NPP changed in these two years.

We'll see later that this paired t-test can also be formulated as a mixed model.

## Interlude - how should we interpret p-values?

An opinionated section on hypothesis testing with p-values.

## Testing for unequal variance

```{r, include=FALSE}
##
## Testing for unequal variance
##
```

Lets take a slightly larger slice of our original dataset now and examine
changes in variance within it. We can create a new dataset with years 2017
to 2020.

```{r}
# Create a 4-year data subset
anpp.2017.2020 <- anpp.annual %>%
  dplyr::filter(year %in% 2017:2020)
```

How would we test whether there are unequal variances within the samples we are
comparing? If we plot the data, we will see some visual cues. Boxplots are a
nice method for this.

```{r}
ggplot(anpp.2017.2020, aes(x = year, y = npp_g_m2, group = year)) +
  geom_boxplot()
```
With the two additional years, we can see that some years, namely 2017, can have
much higher variance than others. We also have some tests we can use to quantify
that range in variance. (@Darren -  I'm not sure what to say on these, and also
not sure why we need the car package)

To give us some access to tests we'll use, lets first use the `car` package.

```{r, message=FALSE}
library(car)
```

```{r}
bartlett.test(npp_g_m2 ~ year, data = anpp.2017.2020)
fligner.test(npp_g_m2 ~ year, data = anpp.2017.2020)
leveneTest(npp_g_m2 ~ as.factor(year), data = anpp.2017.2020) # from car package
```


## Comparing samples with general linear models

```{r, include=FALSE}
##
## Comparing samples with general linear models
##
```

Comparing the mean of different samples, as we have done with t-tests, is also
possible using *General linear models*, a class of procedures used often in
standard statistics that includes linear regression, one- and two-way analysis
of variance (ANOVA), and analysis of covariance (ANCOVA). All of these are
variations of "straight-line-fitting" statistics, and `R` uses the `lm()`
function for all of these procedures. So, instead of comparing sample means
directly, we are essentially compare best-fit lines drawn between the mean
values of the samples.

Lets go back to our 2019 and 2020 dataframe and compare one of these general
linear models to the t-test we did then. A similar mean comparison test can be
done as a linear regression, using `lm` directly. We will fit the model and then
ask for summary results.

```{r}
# Two-sample mean comparison using a linear regression model
lm.ttest <- lm(npp_g_m2 ~ year, data = anpp.2019.2020)
summary(lm.ttest)
```
We get a few details on the linear model fit here, and we see that we have
estimated the same difference in means and the same p-value as we had in the
earlier t-test.

If we want to look at how this model is being fit visually, we can make a plot
using `ggplot`. It allows us to add model to a plot with `geom_smooth`. We need
to specify the type of model as "lm" to get a linear model.

```{r}
ggplot(data=anpp.2019.2020, aes(x=year, y=npp_g_m2)) +
  geom_point() +
  geom_smooth(method="lm")
```

We can also compare the means using one-way ANOVA. The function to do this is
`aov()`, but under the hood this is really just fitting an `lm` model again,
which we can see by looking at the function documentation.

```{r, message=FALSE}
?aov
```

One nuance here is that when given numerical predictor variables, like `year`,
`lm` interprets these as a continuous variable. For ANOVA, we aim to analyze
differences between discrete categories, so we should make sure we are using a
`factor`, which is how `R` represents categorical variables. Lets convert `year`
to a factor first.

```{r}
anpp.2019.2020.f <- anpp.2019.2020
anpp.2019.2020.f$year <- factor(anpp.2019.2020.f$year)
```

Now we can fit the ANOVA model using `aov()`, first specifying the linear model
and dataframe to use, and then ask R for summary statistics.

```{r}
# One-way ANOVA equivalent to the 2-sample t-test
aov.ttest <- aov(npp_g_m2 ~ year, data = anpp.2019.2020.f)
summary(aov.ttest)
car::Anova(lm.ttest, type = "III") # Not clear on difference in outputs, p value is same.
```
Notice that here, and when we used `lm`, our hypothesis test results were the 
same as with the unpaired, equal-variance, two sample t-test that we tried
earlier. This suggests that by default, `lm` is making some assumptions that
our observations are independent. We already know that they aren't. Later, we'll
see some ways to account for this.

When we have two categories in our data, we can also do a multi-way ANOVA by 
adding additional factors to the model. In our case we have an additional
categorical variable, called `zone`, that assigns each NPP site to one of the
five major vegetation zones at Jornada. Since this is a character column,  `lm`,
or `aov`, will interpret that column as a factor, and we can easily fit a 
two-way ANOVA model.

```{r}
# Two-way ANOVA using year and vegetation zone
aov.2way <- aov(npp_g_m2 ~ year + zone, data = anpp.2019.2020.f)
summary(aov.2way)
```
In our two-way ANOVA, we see that vegetation zone has a p-value below 0.05,
which suggests that we might be able to reject the null hypothesis that all the
vegetation zones have the same mean NPP value.

We know that we should be using a paired model, since our observations are not
independent. In ANOVA, the term for this is *repeated measures*. To do this we
must add an "Error" term to our model.

```{r}
# Two-way, repeated measures ANOVA using year and vegetation zone
aov.2way.rm <- aov(npp_g_m2 ~ year + zone + Error(zone/year),
                   data = anpp.2019.2020.f)
summary(aov.2way.rm)
```
Here we have begun to partition our error, or variance. according to different
groups in our data. (@Greg @Darren - this seems like a good place to jump to 
mixed models, but need a better explanation here first...?).

## Interlude - Unequal variance and random effects



## Into the wilderness with linear mixed models
